{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860f2a96-8fef-4201-bde0-3e069a8df97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from shapely.strtree import STRtree\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import os\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import glob\n",
    "import json\n",
    "import openslide\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafb715d-4267-4454-955a-8006a714caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "def get_structure(load_dict,classname):\n",
    "    structure = []\n",
    "    if len(classname) == 1:\n",
    "        for load_dict_i in tqdm(load_dict, desc=f\"Extracting {classname}\"):\n",
    "            if 'classification' in  load_dict_i['properties']:\n",
    "                prop_name = load_dict_i['properties']['classification']['name']\n",
    "                if (prop_name == classname[0]):\n",
    "                    contours = load_dict_i['geometry']['coordinates']\n",
    "                    if (load_dict_i['geometry']['type'] == 'MultiPolygon'):\n",
    "                        for contour in contours:\n",
    "                            points = [pt for pt in contour[0]]\n",
    "                            structure.append(Polygon(points))\n",
    "                    elif (load_dict_i['geometry']['type'] == 'Polygon'):\n",
    "                        for contour in contours:\n",
    "                            points = [pt for pt in contour]\n",
    "                            structure.append(Polygon(points))\n",
    "    elif(len(classname)==2):\n",
    "        for load_dict_i in tqdm(load_dict, desc=f\"Extracting {classname}\"):\n",
    "            if 'classification' in  load_dict_i['properties']:\n",
    "                prop_name = load_dict_i['properties']['classification']['name']\n",
    "                if (prop_name == classname[0] or prop_name==classname[1]):\n",
    "                    contours = load_dict_i['geometry']['coordinates']\n",
    "                    if (load_dict_i['geometry']['type'] == 'MultiPolygon'):\n",
    "                        for contour in contours:\n",
    "                            points = [pt for pt in contour[0]]\n",
    "                            structure.append(Polygon(points))\n",
    "                    elif (load_dict_i['geometry']['type'] == 'Polygon'):\n",
    "                        for contour in contours:\n",
    "                            points = [pt for pt in contour]\n",
    "                            structure.append(Polygon(points))\n",
    "    # result = structure[0]\n",
    "    # for polygon in tqdm(structure[1:],desc=f'Post processing the {classname},N=={len(structure)}'):\n",
    "    #     result = result.union(polygon)\n",
    "    return structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96106217-9d5f-4cf0-bf72-4867d0538cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ['roi']: 100%|███████████████████████| 3/3 [00:00<00:00, 3194.44it/s]\n",
      "Extracting ['roi']: 100%|██████████████████████| 4/4 [00:00<00:00, 23797.47it/s]\n",
      "Extracting ['roi']: 100%|██████████████████████| 4/4 [00:00<00:00, 21959.71it/s]\n",
      "Extracting ['roi']: 100%|██████████████████████| 2/2 [00:00<00:00, 10255.02it/s]\n",
      "Extracting ['roi']: 100%|██████████████████████| 4/4 [00:00<00:00, 13842.59it/s]\n",
      "Extracting ['roi']: 100%|██████████████████████| 4/4 [00:00<00:00, 48629.61it/s]\n"
     ]
    }
   ],
   "source": [
    "json_files = glob.glob(\"/Users/fanfan/Desktop/tubule_paper_KI/KI_resubmission/bar_figure/json/*.json\")\n",
    "for json_file in json_files:\n",
    "    wsiid = os.path.basename(json_file).split('.json')[0]\n",
    "    wsi_file = glob.glob(f\"/Volumes/data/Neptune/FSGS_MCD/USE_TUBULE/{wsiid}*\")[0]\n",
    "    with open(json_file, 'r') as load_f:\n",
    "       load_dict = json.load(load_f)\n",
    "    cortexs = get_structure(load_dict,classname=['roi'])\n",
    "    x_min, y_min, x_max, y_max = cortexs[0].bounds\n",
    "    slide = openslide.OpenSlide(wsi_file)\n",
    "    pas = cv2.cvtColor(\n",
    "        np.asarray(slide.read_region((int(x_min), int(y_min)), 0, (1000,1000)))[:, :,\n",
    "        0:3], cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'/Users/fanfan/Desktop/tubule_paper_KI/KI_resubmission/bar_figure/json/{wsiid}_{x_min}_{y_min}.png',pas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "759f44ec-4d4f-402d-baf4-84459e4d05af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ['roi']: 100%|███████████████████████| 2/2 [00:00<00:00, 7810.62it/s]\n"
     ]
    }
   ],
   "source": [
    "json_files = glob.glob(\"/Users/fanfan/Desktop/tubule_paper_KI/KI_resubmission/bar_figure/json/16*.json\")\n",
    "for json_file in json_files:\n",
    "    wsiid = os.path.basename(json_file).split('.json')[0]\n",
    "    wsi_file = glob.glob(f\"/Volumes/data/UMich/WSI/pas/{wsiid}*\")[0]\n",
    "    with open(json_file, 'r') as load_f:\n",
    "       load_dict = json.load(load_f)\n",
    "    cortexs = get_structure(load_dict,classname=['roi'])\n",
    "    x_min, y_min, x_max, y_max = cortexs[0].bounds\n",
    "    slide = openslide.OpenSlide(wsi_file)\n",
    "    pas = cv2.cvtColor(\n",
    "        np.asarray(slide.read_region((int(x_min), int(y_min)), 0, (1000,1000)))[:, :,\n",
    "        0:3], cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'/Users/fanfan/Desktop/tubule_paper_KI/KI_resubmission/bar_figure/json/{wsiid}_{x_min}_{y_min}.png',pas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff9605-ddd1-4fdc-a629-9cd9880c3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file, 'r') as load_f:\n",
    "       load_dict = json.load(load_f)\n",
    "    wsiid = (os.path.basename(json_file)).split('.json')[0]\n",
    "    bid = wsiid\n",
    "    # for i in range(len(column)):\n",
    "    #     info = column[i]\n",
    "    #     filename = info['filename']\n",
    "    #     if (wsiid in filename):\n",
    "    #         bid = info['biopsyid']\n",
    "    print(f'###### {bid} ##### {wsiid} #######')\n",
    "    if (os.path.exists(f'{par_path}/{bid}')==True):\n",
    "        print('FILES EXIST!')\n",
    "    else:\n",
    "        slide = read_wsi_curegn(wsiid,wsi_path_par)\n",
    "        create_all_folders(bid,par_path)\n",
    "        print('Get cortex data...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
